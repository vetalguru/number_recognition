// Copyright (c) 2025 Vitalii Shkibtan. All rights reserved.

#include "include/application.h"

#include <algorithm>
#include <iostream>  // For help and version output
#include <filesystem>  // NOLINT(build/c++17)
#include <fstream>
#include <sstream>
#include <string>
#include <utility>
#include <vector>

#include <boost/json.hpp>
#include <boost/program_options.hpp>

// Autogenerated file with current application version
#include "version.h"  // NOLINT (build/include_subdir)

#include "include/logger.hpp"
#include "include/mnistcsvdataset.hpp"


// Unnamed namespace to restrict the scope of constants to this translation unit
namespace {
constexpr char kDefaultHiddenLayers[] = "512";
constexpr int kDefaultEpochs = 40;
constexpr double kDefaultLearningRate = 0.001;
constexpr char kMnistCsvDelimeter = ',';
}

std::string Application::version() const {
    std::ostringstream ss;
    ss << static_cast<int>(VERSION_MAJOR) << "."
       << static_cast<int>(VERSION_MINOR) << "."
       << VERSION_BUILD;

    return ss.str();
}

template<typename T>
bool Application::getValue(const po::variables_map& aVm,
                           const std::string& aKey,
                           T& aOut,
                           const std::string& aLabel) const {
    try {
        aOut = aVm.at(aKey).as<T>();
    } catch (const std::exception& e) {
        LOG_ERROR << "Invalid or missing " << aLabel << ". " << e.what();
        return false;
    }
    return true;
}

std::vector<size_t> Application::parseLayersString(const std::string& aInput,
    size_t aImageSize, size_t aNumClasses) const {
    std::vector<size_t> result;
    std::stringstream ss(aInput);
    std::string item;

    result.push_back(aImageSize);
    while (std::getline(ss, item, ',')) {
        result.push_back(std::stoul(item));
    }
    result.push_back(aNumClasses);

    return result;
}

std::string Application::vectorToString(const std::vector<size_t>& aVector,
                           char aDelimiter) const {
    std::ostringstream oss;
    for (size_t i = 0; i < aVector.size(); ++i) {
        if (i != 0) {
            oss << aDelimiter;
        }
        oss << aVector[i];
    }
    return oss.str();
}

std::vector<double> Application::toOneHot(
    uint8_t aLabel, size_t aNumClasses) const {
    std::vector<double> vec(aNumClasses, 0.0);
    vec[aLabel] = 1.0;
    return vec;
}

std::vector<double> Application::normalizeImage(
    const MnistCsvDataSet::Image_t& image) const {
    std::vector<double> result(image.size());

    std::transform(image.begin(), image.end(), result.begin(),
                   [](uint8_t px) { return static_cast<double>(px) / 255.0; });

    return result;
}

void Application::parseCommandLine(const int aArgc,
                                   const char* const aArgv[]) const {
    std::string taskType;

    po::options_description mainDesc{"General options"};
    mainDesc.add_options()
        ("help,h", "Show help message")
        ("version,v", "Show version")
        ("mode,m", po::value<std::string>(&taskType)->required(),
            "Select mode: training, recognition");

    po::options_description trainDesc("Training options:");
    trainDesc.add_options()
        ("train-data,t", po::value<std::string>(),
            "Path to train csv file (mnist_train.csv)")
        ("test-data,c", po::value<std::string>(),
            "Path to data file csv (mnist_test.csv)")
        ("output-model,o", po::value<std::string>(),
            "Output file with trained model and network configuration")
        ("epochs,e", po::value<int>()->default_value(kDefaultEpochs),
            "Number of epochs to learning (Supported values: 1 - 100)")
        ("learning-rate,l",
            po::value<double>()->default_value(kDefaultLearningRate),
            "Learning rate for optimizer. Typical values: 0.1â€“0.001")
        ("hidden-layers,s",
            po::value<std::string>()->default_value(kDefaultHiddenLayers),
            "Comma-separated list of hidden layer sizes, e.g., 768,512,256,10");

    po::options_description recDesc("Recognition options");
    recDesc.add_options()
        ("data,d", po::value<std::string>(),
            "Path to file with data to recognize")
        ("model,p", po::value<std::string>(),
            "Path to file with learned model")
        ("result,r", po::value<std::string>(),
            "Output file with recognition results");

    mainDesc.add(trainDesc).add(recDesc);

    po::variables_map vm;
    try {
        po::store(po::parse_command_line(aArgc, aArgv, mainDesc), vm);

        if (vm.count("version")) {
            std::cout << version() << std::endl;
            return;
        }

        if (vm.count("help")) {
            std::cout << mainDesc << std::endl;
            return;
        }

        po::notify(vm);
    } catch (const po::error& e) {
        LOG_ERROR << "Error: Unable to parse command line with error: "
                  << e.what();
        return;
    }

    if (taskType == "training") {
        initTrainingMode(vm);
    } else if (taskType == "recognition") {
        initRecognitionMode(vm);
    } else {
        LOG_ERROR << "Unknown mode. Valid modes are 'training'"
            << " and 'recognition'.";
    }
}

void Application::initTrainingMode(const po::variables_map& aVm) const {
    std::string trainFile;
    std::string testFile;
    std::string outputFile;
    std::vector<size_t> layers;
    int epochs;
    double learningRate;
    std::string hiddenLayersString;

    if (!getValue(aVm, "train-data", trainFile, "--train-data")      ||
        !getValue(aVm, "test-data", testFile, "--test-data")         ||
        !getValue(aVm, "output-model", outputFile, "--output-model") ||
        !getValue(aVm, "epochs", epochs, "--epochs")                 ||
        !getValue(aVm, "learning-rate", learningRate, "--learning-rate") ||
        !getValue(aVm, "hidden-layers", hiddenLayersString,
                  "--hidden-layers")) {
        return;
    }

    layers = parseLayersString(hiddenLayersString);

    handleTrainingMode(trainFile, testFile, outputFile,
                       layers, epochs, learningRate);
}

void Application::initRecognitionMode(const po::variables_map& aVm) const {
    std::string dataFile;
    std::string modelFile;
    std::string resultFile;

    if (!getValue(aVm, "data", dataFile, "--data") ||
        !getValue(aVm, "model", modelFile, "--model") ||
        !getValue(aVm, "result", resultFile, "--result")) {
        return;
    }

    LOG_INFO << "Recognition mode parameters:" << "\n"
             << "\tData file:\t" << dataFile << "\n"
             << "\tModel file:\t" << modelFile << "\n"
             << "\tResult file:\t" << resultFile;

    handleRecognitionMode(dataFile, modelFile, resultFile);
}

bool Application::saveModelToJson(const std::string& aFileName,
    const Perceptron& aNetwork) const {
    if (aFileName.empty()) {
        LOG_ERROR << "Empty JSON file name";
        return false;
    }

    if (std::filesystem::exists(aFileName)) {
        LOG_ERROR << "File " << aFileName << " already exists";
        return false;
    }

    if (!aNetwork.isConfigured()) {
        LOG_ERROR << "Network is not configured";
        return false;
    }

    if (!aNetwork.isTrained()) {
        LOG_ERROR << "Network is not trained";
        return false;
    }

    boost::json::object jsonModel;
    jsonModel["architecture"] = boost::json::array();
    jsonModel["layers"] = boost::json::array();

    // Fill architecture
    try {
        // Add first (input) layer
        if (!aNetwork.layers().empty()) {
            jsonModel["architecture"].as_array().emplace_back(kImageSize);
        }

        for (const auto& layer : aNetwork.layers()) {
            jsonModel["architecture"].as_array().emplace_back(
                static_cast<int>(layer.size()));
        }
    } catch (const std::exception& e) {
        LOG_ERROR << "Unable to fill JSON architecture with error " << e.what();
        return false;
    }

    // Fill layers and weights
    try {
        for (const auto& layer : aNetwork.layers()) {
            boost::json::object layerJson;
            layerJson["neurons"] = boost::json::array();

            for (const auto& neuron : layer) {
                boost::json::object neuronJson;
                neuronJson["bias"] = neuron.bias();
                neuronJson["weights"] = boost::json::array();

                for (const auto& weight : neuron.cweights()) {
                    neuronJson["weights"].as_array().emplace_back(weight);
                }

                layerJson["neurons"].as_array().emplace_back(neuronJson);
            }

            jsonModel["layers"].as_array().emplace_back(layerJson);
        }
    } catch (const std::exception& e) {
        LOG_ERROR << "Unable to fill layers and biases to JSON with error"
            << e.what();
        return false;
    }

    // Save to JSON
    std::ofstream file(aFileName);
    if (!file.is_open()) {
        LOG_ERROR << "Unable to open file " << aFileName;
        return false;
    }

    try {
        file << boost::json::serialize(jsonModel) << std::endl;
    } catch (const std::exception& e) {
        LOG_ERROR << "Unable to write JSON to the file " << aFileName
            << " with error " << e.what();
        return false;
    }

    file.close();

    LOG_INFO << "Model saved to " << aFileName;

    return true;
}

bool Application::loadModelFromJson(const std::string& aFileName,
    Perceptron& aNetwork) const {
    if (aFileName.empty()) {
        LOG_ERROR << "Empty JSON file name";
        return false;
    }

    if (!std::filesystem::exists(aFileName)) {
        LOG_ERROR << "File " << aFileName << " does not exist";
        return false;
    }

    std::ifstream file(aFileName);
    if (!file.is_open()) {
        LOG_ERROR << "Unable to open file " << aFileName;
        return false;
    }

    std::stringstream buffer;
    buffer << file.rdbuf();
    file.close();

    boost::json::value parsedJson;
    try {
        parsedJson = boost::json::parse(buffer.str());
    } catch (const std::exception& e) {
        LOG_ERROR << "Unable to parse JSON from file "
            << aFileName << " with error: " << e.what();
        return false;
    }

    boost::json::object jsonModel = parsedJson.as_object();
    // Check if JSON has required fields and types
    if (!jsonModel.contains("architecture") ||
        !jsonModel["architecture"].is_array() ||
        !jsonModel.contains("layers") ||
        !jsonModel["layers"].is_array()) {
        LOG_ERROR << "Invalid JSON format in file " << aFileName;
        return false;
    }

    // Read architecture
    std::vector<size_t> architecture;
    try {
        for (const auto& layerSize : jsonModel["architecture"].as_array()) {
            if (!layerSize.is_number()) {
                LOG_ERROR << "Invalid layer size in JSON file " << aFileName;
                return false;
            }

            architecture.emplace_back(layerSize.as_int64());
        }
    }
    catch(const std::exception& e) {
        LOG_ERROR << "Unable to read architecture from file "
            << aFileName << " with error: " << e.what();
        return false;
    }

    if (architecture.empty()) {
        LOG_ERROR << "Wrong network architecture in file " << aFileName;
        return false;
    }

    // Set architecture
    if (!aNetwork.initializeNetwork(architecture)) {
        LOG_ERROR << "Unable to configure network";
        return false;
    }

    const auto& jsonLayers = jsonModel["layers"].as_array();
    if (jsonLayers.size() != architecture.size() - 1) {
        LOG_ERROR
            << "Mismatch between architecture and number of layers in JSON";
        return false;
    }

    // Read weights and biases
    try {
        for (size_t layerIndex = 0; layerIndex < jsonLayers.size();
            ++layerIndex) {
            const auto& jsonLayer = jsonLayers[layerIndex];
            for (size_t neuronIndex = 0;
                    neuronIndex <
                        jsonLayer.at("neurons").as_array().size();
                    ++neuronIndex) {
                const auto& neuronJson =
                    jsonLayer.at("neurons").as_array()[neuronIndex];

                const auto& weightsJson =
                    neuronJson.at("weights").as_array();
                std::vector<double> weights;
                for (const auto& weight : weightsJson) {
                    weights.emplace_back(weight.as_double());
                }

                aNetwork.setNeuronWeights(layerIndex, neuronIndex, weights);
                aNetwork.setNeuronBias(layerIndex, neuronIndex,
                    neuronJson.at("bias").as_double());
            }
        }
    } catch (const std::exception& e) {
        LOG_ERROR << "Unable to read weights and biases from file "
            << aFileName << " with error " << e.what();
        return false;
    }

    LOG_INFO << "Model successfully loaded from " << aFileName;
    return true;
}

int Application::run(const int aArgc, const char* const aArgv[]) const {
    parseCommandLine(aArgc, aArgv);
    return EXIT_SUCCESS;
}

void Application::handleTrainingMode(const std::string& aMnistTrainFile,
                                     const std::string& aMnistTestFile,
                                     const std::string& aOutputModelFile,
                                     const std::vector<size_t>& aLayers,
                                     const int aEpochs,
                                     const double aLearningRate) const {
    if (!std::filesystem::exists(aMnistTrainFile)) {
        LOG_ERROR<< "Train file " << aMnistTrainFile << " does not exist";
        return;
    }

    if (!std::filesystem::exists(aMnistTestFile)) {
        LOG_ERROR << "Test file " << aMnistTestFile << "does not exist";
        return;
    }

    if (std::filesystem::exists(aOutputModelFile)) {
        LOG_ERROR << "Output file " << aOutputModelFile << " already exists";
        return;
    }

    if (aLayers.size() < 3) {
        LOG_ERROR << "Layer counter less than minimum layers number(3)";
        return;
    }

    if (aEpochs <= 0 || aEpochs > 100) {
        LOG_ERROR << "Epochs value wrong on not effective: "
                  << aEpochs;
        return;
    }

    if (aLearningRate >= 0.5 || aLearningRate < 0.00001) {
        LOG_ERROR << "Learning rate value wrong on not effective: "
                  << aLearningRate;
        return;
    }

    std::string layersStr = vectorToString(aLayers);

    LOG_INFO << "Training mode parameters:\n"
             << "\tTrain file\t:\t" << aMnistTrainFile << "\n"
             << "\tTest file\t:\t" << aMnistTestFile << "\n"
             << "\tModel file\t:\t" << aOutputModelFile << "\n"
             << "\tLayers model\t:\t" << layersStr << "\n"
             << "\tEpochs num\t:\t" << aEpochs << "\n"
             << "\tLearning rate\t:\t" << aLearningRate;

    auto function = Neuron::ActivationFunction::SIGMOID;
    Perceptron network(aLayers, function);

    // Load train data
    std::vector<std::vector<double>> trainInputs;
    std::vector<std::vector<double>> trainTargets;
    {
        MnistCsvDataSet trainSet(aMnistTrainFile);
        if (!trainSet.isLoaded()) {
            LOG_ERROR
                << "Unable to load MNIST data from file "
                << aMnistTrainFile;
            return;
        }

        trainInputs.resize(trainSet.size());
        trainTargets.resize(trainSet.size());
        for (size_t i = 0; i < trainSet.size(); ++i) {
            trainTargets[i] = toOneHot(trainSet[i].first);
            trainInputs[i] = normalizeImage(trainSet[i].second);
        }
    }

    // Train model
    LOG_INFO << "Training started...";
    network.train(trainInputs, trainTargets, aEpochs, aLearningRate);
    LOG_INFO << "Training finished";

    // Load test data
    std::vector<std::vector<double>> testInputs;
    std::vector<std::vector<double>> testTargets;
    {
        MnistCsvDataSet testSet(aMnistTestFile);
        if (!testSet.isLoaded()) {
            LOG_ERROR
                << "Unable to load MNIST data from file "
                << aMnistTrainFile;
            return;
        }

        testInputs.resize(testSet.size());
        testTargets.resize(testSet.size());
        for (size_t i = 0; i < testSet.size(); ++i) {
            testTargets[i] = toOneHot(testSet[i].first);
            testInputs[i] = normalizeImage(testSet[i].second);
        }
    }

    int correct = 0;
    for (size_t i = 0; i < testInputs.size(); ++i) {
        std::vector<double> output =
            network.forward(testInputs[i]).back();

        // Get predicted number (Max number from predicted)
        int predicted = std::distance(output.begin(),
            std::max_element(output.begin(), output.end()));
        int actual = std::distance(testTargets[i].begin(),
            std::max_element(testTargets[i].begin(),
            testTargets[i].end()));

        if (predicted == actual) {
            ++correct;
        }
    }

    LOG_INFO << "Accuracy: " << (correct * 100.0 / testInputs.size()) << "%";

    // Save model to JSON
    if (!saveModelToJson(aOutputModelFile, network)) {
        LOG_ERROR << "Unable to save model to JSON";
    } else {
        LOG_INFO << "Model saved to model.json";
    }
}

void Application::handleRecognitionMode(const std::string& aDataFile,
                                        const std::string& aModelFile,
                                        const std::string& aResultFile) const {
    LOG_INFO << "Recognition started...";

    if (!std::filesystem::exists(aModelFile)) {
        LOG_ERROR << "Model file " << aModelFile << " does not exist";
        return;
    }

    if (!std::filesystem::exists(aDataFile)) {
        LOG_ERROR << "Data file " << aDataFile << " does not exist";
        return;
    }

    // Load model
    Perceptron network;
    if (!loadModelFromJson(aModelFile, network)) {
        LOG_ERROR << "Failed to load model from " << aModelFile;
        return;
    }

    // Load data
    std::vector<std::vector<double>> inputData;
    std::vector<std::vector<double>> dummyTarget;
    {
        MnistCsvDataSet testSet(aDataFile);
        if (!testSet.isLoaded()) {
            LOG_ERROR << "Unable to load MNIST data from file " << aDataFile;
            return;
        }

        inputData.resize(testSet.size());
        dummyTarget.resize(testSet.size());
        for (size_t i = 0; i < testSet.size(); ++i) {
            dummyTarget[i] = toOneHot(testSet[i].first);
            inputData[i] = normalizeImage(testSet[i].second);
        }
    }

    double minPixel =
        *std::min_element(inputData[0].begin(), inputData[0].end());
    double maxPixel =
        *std::max_element(inputData[0].begin(), inputData[0].end());
    LOG_INFO << "Pixel value range: [" << minPixel << ", " << maxPixel << "]";

    std::ofstream resultFile(aResultFile);
    if (!resultFile.is_open()) {
        LOG_ERROR << "Unable to create result file " << aResultFile;
        return;
    }

    // Recognize
    size_t matches = 0;
    for (size_t i = 0; i < inputData.size(); ++i) {
        std::vector<double> output = network.forward(inputData[i]).back();

        auto maxPredictElementIter =
            std::max_element(output.begin(), output.end());
        int predictedClass =
            std::distance(output.begin(), maxPredictElementIter);

        int expectedClass = -1;
        if (!dummyTarget[i].empty()) {
            auto maxExpectedElementIter =
                std::max_element(dummyTarget[i].begin(), dummyTarget[i].end());
            expectedClass =
                std::distance(dummyTarget[i].begin(), maxExpectedElementIter);
        } else {
            LOG_ERROR << "Empty target at index " << i;
            continue;
        }

        // Write result to file
        resultFile << "Expected: " << expectedClass
            << "\tPredicted: " << predictedClass << std::endl;

        if (expectedClass == predictedClass) {
            ++matches;
        }
    }

    LOG_INFO << "Matches: " << matches << " of " << inputData.size();
    LOG_INFO << "Recognition accuracy: " <<
        (matches * 100.0 / inputData.size()) << "%";
    LOG_INFO << "Recognition completed. Result saved to file " << aResultFile;
}
